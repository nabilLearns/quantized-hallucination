transformers
accelerate
datasets
optimum
peft
# auto-gptq # not in use (yet)
bitsandbytes # needs a GPU
scikit-learn
matplotlib
tqdm
hydra-core
omegaconf
pyyaml
huggingface_hub
llama-cpp-python # use it for gguf models ; it seems that HF de-quantizes wts
gguf
hf_xet

torch # maybe specify specific version?