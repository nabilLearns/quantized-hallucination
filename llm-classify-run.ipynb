{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb2d9fc-0f56-4582-b75c-8403cdd30022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  7 20:15:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:42:00.0 Off |                    0 |\n",
      "| N/A   43C    P0             54W /  250W |   29433MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d153ff6e-55f6-466c-8d50-d91ba5eaae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers accelerate datasets optimum peft auto-gptq bitsandbytes scikit-learn torch --quiet\n",
    "!pip install flash-attn --no-build-isolation --quiet # for qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96cea69-0725-40d6-891c-56327701f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UTAustin-AIHealth/MedHallu dataset (pqa_labeled)...\n",
      "Limiting dataset to 16 samples for testing.\n",
      "Loading tokenizer for Qwen/Qwen2.5-7B-Instruct...\n",
      "Setting up Qwen/Qwen2.5-7B-Instruct with quantization: None...\n",
      "Loading uncompressed model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fc8ccee0e1458197e90551a102f275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen/Qwen2.5-7B-Instruct model loaded successfully!\n",
      "{'': device(type='cuda', index=0)}\n",
      "Preparing prompts\n",
      "Prompts are prepared.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, GPTQConfig, BitsAndBytesConfig\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import gc # garbage collector interface\n",
    "import pprint\n",
    "from typing import List, Tuple\n",
    "\n",
    "# --- Configuration --- (flexible: MODEL_NAME, DATASET_CONFIG, BATCH_SIZE, MAX_SAMPLES, QUANTIZATION_MODE, OUTPUT_FILENAME)\n",
    "MODEL_NAME = 'Qwen/Qwen2.5-7B-Instruct' # try different models later\n",
    "DATASET_NAME = 'UTAustin-AIHealth/MedHallu'\n",
    "DATASET_CONFIG = 'pqa_labeled' # try adding pqa_artiifcal later\n",
    "BATCH_SIZE = 8\n",
    "MAX_SAMPLES = 16 #1000 # switch back\n",
    "QUANTIZATION_MODE = None #'8bit_bnb'\n",
    "OUTPUT_FILENAME = f'hallucination_results_{MODEL_NAME}_{QUANTIZATION_MODE}_{DATASET_CONFIG}.csv'\n",
    "\n",
    "# --- Load Dataset ---\n",
    "print(f'Loading {DATASET_NAME} dataset ({DATASET_CONFIG})...')\n",
    "ds = load_dataset(DATASET_NAME, DATASET_CONFIG)\n",
    "dataset = ds['train'] # use train split which has 1k labelled samples\n",
    "\n",
    "if MAX_SAMPLES is not None:\n",
    "    print(f'Limiting dataset to {MAX_SAMPLES} samples for testing.')\n",
    "    dataset = dataset.select(range(MAX_SAMPLES)) # for N rows, there are 2*N answers for hallucination-detection LLM to classify (1 gt, 1 hallucinated answers)\n",
    "\n",
    "# --- Setup Model and Tokenizer\n",
    "print(f'Loading tokenizer for {MODEL_NAME}...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True, padding_side=\"left\") # was getting an error when trying to run inference on inputs with default padding_side = right\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token # set pad token for batching if not present\n",
    "\n",
    "print(f'Setting up {MODEL_NAME} with quantization: {QUANTIZATION_MODE}...')\n",
    "\n",
    "quantization_config = None\n",
    "if QUANTIZATION_MODE == '8bit_bnb':\n",
    "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "elif QUANTIZATION_MODE == '4bit_bnb':\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "elif QUANTIZATION_MODE == '4bit_gptq':\n",
    "    quantization_config = GPTQConfig(bits=4, dataset='c4', tokenizer=tokenizer)\n",
    "else:\n",
    "    print(\"Loading uncompressed model\")\n",
    "\n",
    "model_kwargs = {\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"device_map\": \"auto\",\n",
    "    \"attn_implementation\": \"eager\", #\"flash_attention_2\", ; doesn't work on Volta GPU (old) ; so ignoring this for now ; may revisit if I need to speed up inference\n",
    "    \"torch_dtype\": torch.float16, # torch.bfloat16 for ampere, maybe not best on older Volta GPU\n",
    "    \"trust_remote_code\": True\n",
    "}\n",
    "\n",
    "if QUANTIZATION_MODE == \"none\":\n",
    "    model_kwargs.pop(\"quantization_config\")\n",
    "elif QUANTIZATION_MODE == \"4bit_gptq\":\n",
    "    model_kwards.pop(\"torch_dtype\")\n",
    "\n",
    "try:\n",
    "    if 'model' in globals():\n",
    "        del model\n",
    "    if 'classifier' in globals():\n",
    "        del classifier\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, **model_kwargs)\n",
    "    print(f\"{MODEL_NAME} model loaded successfully!\")\n",
    "    print(model.hf_device_map)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "    raise e\n",
    "\n",
    "# --- Setup Pipeline ---\n",
    "classifier = pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# --- Define Prompting Function ---\n",
    "# used in the paper\n",
    "original_system_prompt = \"\"\"\n",
    "You are an AI assistant with extensive knowledge in the field of medicine. I want you act as an answer judge. Given a question and an\n",
    "answer, your objective is to determine if the provided answer contains non-factual or hallucinated information. You SHOULD give your judgement based\n",
    "on the following hallucination types and the world knowledge.\n",
    "\n",
    "You are trying to determine if there is a factual contradiction between the answer and the world knowledge.\n",
    "Some information in the answer might be fabricated. Answer '0' if the answer is factual and '1' if the answer is hallucinated.\n",
    "You can categorize the answer as hallucinated if it falls in either of the category:\n",
    "\n",
    "Type: Misinterpretation of #Question#: These are hallucinated answers that misunderstands the question, leading to an off-topic or\n",
    "irrelevant response.\n",
    "Type: Incomplete Information: These are hallucinated answers that Point out what is not true without providing correct information.\n",
    "Type: Mechanism and Pathway Misattribution - These are hallucinated answer that falsely attribution of biological mechanisms,\n",
    "molecular pathways, or disease processes that contradicts established medical knowledge\n",
    "Type: Methodological and Evidence Fabrication - Inventing false research methods, statistical data, or specific clinical outcomes\n",
    "\n",
    "Do not return anything else, just the answer.\n",
    "Return just an integer value, '0' if the answer is factual and '1' if the answer is hallucinated. No letter or word, just the integer value.\n",
    "\"\"\"\n",
    "\n",
    "# modification on our part to allow model to refrain from making a classification if it is not sure\n",
    "not_sure_system_prompt = \"\"\"\n",
    "You are an AI assistant with extensive knowledge in the field of medicine. I want you act as an answer judge. Given a question, an\n",
    "answer, and relevant World Knowledge, determine if the provided answer is factual or contains hallucinated information based on the knowledge provided and established medical facts.\n",
    "\n",
    "- If the answer is factual and consistent with world knowledge, return '0'.\n",
    "- If the answer contains non-factual, hallucinated, or contradictory information based on the knowledge provided or established medical facts (e.g., Misinterpretation, Incomplete Info, Mechanism Misattribution, Fabrication), return '1'.\n",
    "- If you are genuinely uncertain or cannot make a definitive judgement based on the provided context and your medical knowledge, return '2'.\n",
    "\n",
    "Do not return anything else, just the integer value.\n",
    "\n",
    "Return '0' for factual, '1' for hallucinated, '2' for not sure.\n",
    "\n",
    "You can categorize the answer as hallucinated if it falls in either of the category:\n",
    "\n",
    "Type: Misinterpretation of #Question#: These are hallucinated answers that misunderstands the question, leading to an off-topic or\n",
    "irrelevant response.\n",
    "Type: Incomplete Information: These are hallucinated answers that Point out what is not true without providing correct information.\n",
    "Type: Mechanism and Pathway Misattribution - These are hallucinated answer that falsely attribution of biological mechanisms,\n",
    "molecular pathways, or disease processes that contradicts established medical knowledge\n",
    "Type: Methodological and Evidence Fabrication - Inventing false research methods, statistical data, or specific clinical outcomes\n",
    "\n",
    "Do not return anything else, just the answer.\n",
    "Return just an integer value, '0' if the answer is factual, '1' if the answer is hallucinated, '2' if not sure. No letter or word, just the integer value.\n",
    "\"\"\"\n",
    "\n",
    "not_sure_system_prompt2 = \"\"\"\n",
    "You are an AI judge with extensive knowledge in the field of medicine. I want you act as an answer judge. Given World Knowledge, a Question, and an Answer:\n",
    "- Return '0' if the Answer is factual based on the Knowledge and your understanding of medicine.\n",
    "- Return '1' if the Answer is hallucinated based on the Knowledge and/or your understanding of medicine.\n",
    "- Return '2' if you are unsure.\n",
    "\n",
    "You SHOULD give your judgement based on the following hallucination types and the world knowledge.\n",
    "You are trying to determine if there is a factual contradiction between the answer and the world knowledge.\n",
    "Some information in the answer might be fabricated. Answer '0' if the answer is factual, '1' if the answer is hallucinated, '2' if you are unsure.\n",
    "\n",
    "Output only the single digit 0, 1, or 2 and nothing else.\n",
    "\n",
    "You can categorize the answer as hallucinated if it falls in either of the category:\n",
    "\n",
    "Type: Misinterpretation of #Question#: These are hallucinated answers that misunderstands the question, leading to an off-topic or\n",
    "irrelevant response.\n",
    "Type: Incomplete Information: These are hallucinated answers that Point out what is not true without providing correct information.\n",
    "Type: Mechanism and Pathway Misattribution - These are hallucinated answer that falsely attribution of biological mechanisms,\n",
    "molecular pathways, or disease processes that contradicts established medical knowledge\n",
    "Type: Methodological and Evidence Fabrication - Inventing false research methods, statistical data, or specific clinical outcomes\n",
    "\n",
    "Do not return anything else, just the answer.\n",
    "Return just an integer value, '0' if the answer is factual, '1' if the answer is hallucinated, or '2'. No letter or word, just the integer value.\n",
    "\"\"\"\n",
    "\n",
    "def format_prompt_chatml(knowledge: str, question: str, answer: str) -> List[int]:\n",
    "    few_shot_not_sure_user_content = f\"\"\"\n",
    "    World Knowledge: [Example Knowledge Snippet]\n",
    "    Question: [Example Question]\n",
    "    Answer: [Example Factual Answer]\n",
    "    Your Judgement: 0\n",
    "    \n",
    "    World Knowledge: [Example Knowledge Snippet 2]\n",
    "    Question: [Example Question 2]\n",
    "    Answer: [Example Hallucinated Answer]\n",
    "    Your Judgement: 1\n",
    "    \n",
    "    World Knowledge: [Example Knowledge Snippet 3 - where answer might be ambiguous or knowledge insufficient]\n",
    "    Question: [Example Question 3]\n",
    "    Answer: [Example Ambiguous Answer or Answer unrelated to Knowledge]\n",
    "    Your Judgement: 2\n",
    "    \n",
    "    --- Now your turn ---\n",
    "    World Knowledge: {knowledge}\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    Return just '0' (factual), '1' (hallucinated), or '2' (not sure).\n",
    "    Your Judgement:\"\"\"\n",
    "\n",
    "    original_user_content = f\"\"\"\"\n",
    "    World Knowledge: {knowledge}\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "\n",
    "    Return just an integer value, '0' if the answer is factual, and '1' if the answer is hallucinated. No letter or word, just the integer value.\n",
    "    \n",
    "    Your Judgement:\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": original_system_prompt.strip()}, # remove leading/trailing whitespaces with .strip()\n",
    "        {\"role\": \"user\", \"content\": original_user_content.strip()} # original meaning, from the MedHallu paper\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "# --- Inference and Evaluation ---\n",
    "all_prompts = [] # all string prompts\n",
    "all_ground_truths = [] # corresponding labels for each prompt (0: truth, 1: hallucinated)\n",
    "\n",
    "print(\"Preparing prompts\")\n",
    "for i, row in enumerate(dataset):\n",
    "    knowledge = row[\"Knowledge\"]\n",
    "    question = row[\"Question\"]\n",
    "    hallucinated_answer = row[\"Hallucinated Answer\"]\n",
    "    ground_truth_answer = row[\"Ground Truth\"]\n",
    "\n",
    "    # create prompts for hallucinated and ground truth answers\n",
    "    prompt_hallucinated = format_prompt_chatml(knowledge, question, hallucinated_answer) # type: list of integers (tokens)\n",
    "    prompt_truth = format_prompt_chatml(knowledge, question, ground_truth_answer)\n",
    "\n",
    "    all_prompts.append(prompt_hallucinated)\n",
    "    all_ground_truths.append(1)\n",
    "    all_prompts.append(prompt_truth)\n",
    "    all_ground_truths.append(0)\n",
    "\n",
    "print(\"Prompts are prepared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcb01657-9015-4704-b362-41bae760bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch inference on 32 prompts...\n",
      "Inference complete. Processing Results.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting batch inference on {len(all_prompts)} prompts...\")\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(\n",
    "        all_prompts,\n",
    "        max_new_tokens=1,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "print(\"Inference complete. Processing Results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c4de22-5def-48b1-ba9b-568457dc5830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '!'}\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '0'}\n",
      "text start:  0\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '0'}\n",
      "text start:  0\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '0'}\n",
      "text start:  0\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n",
      "{'role': 'assistant', 'content': '1'}\n",
      "text start:  1\n",
      "{'role': 'assistant', 'content': '!'}\n",
      "text start:  !\n"
     ]
    }
   ],
   "source": [
    "# -- Process Results -- \n",
    "predictions = []\n",
    "raw_outputs = []\n",
    "\n",
    "def parse_prediction(generated_text):\n",
    "    \"\"\"Extract the '0' or '1' from generated text, in case model does not listen to instructions and adds other tokens\"\"\"\n",
    "    text = generated_text.strip()\n",
    "    text_start = text[-10:]\n",
    "    #print(\"text start: \", text_start)\n",
    "    if '0' in text_start:\n",
    "        return 0\n",
    "    elif '1' in text_start:\n",
    "        return 1\n",
    "    elif '2' in text_start:\n",
    "        return 2\n",
    "    else:\n",
    "        #print(f\"Could not parse '0' or '1' from model output: {text}\")\n",
    "        return -1\n",
    "\n",
    "#pprint.pp(outputs[0][0]['generated_text'][2])\n",
    "# outputs[0] : list[dict]\n",
    "# outputs[0][0]: dict\n",
    "# outputs[0][0]['generated_text'] : list[dict] ; idx 0: system, idx 1: user, idx 2: assisstant\n",
    "# outputs[0][0]['generated_text'][-1] : dict\n",
    "\n",
    "# iterate through each output, process it, and append to lists for predictions and raw model outputs\n",
    "for i, output in enumerate(outputs):\n",
    "    full_chat = output[0]['generated_text'] # this INCLUDES the prompt ; we only want newly generated text\n",
    "    assistant_response_dict = full_chat[-1]\n",
    "    #print(assistant_response_dict)\n",
    "    model_response = None\n",
    "    if assistant_response_dict['role'] == 'assistant':\n",
    "        model_response = assistant_response_dict['content']\n",
    "    \n",
    "    pred = parse_prediction(model_response)\n",
    "    predictions.append(pred)\n",
    "    raw_outputs.append(model_response) # store the raw '!!!!!' or '0' or '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c138d55-a7ab-4c24-bd36-02466b6c1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Assemble final results ---\n",
    "def filter_invalid_pairs(pairs: list[tuple[int, int]]):\n",
    "    \"\"\"filter out any results where the model did not produce a valid output (i.e. anything other than 0 or 1)\"\"\"\n",
    "    valid_pairs = []\n",
    "    for pair in pairs:\n",
    "        if pair[1] == -1:\n",
    "            pass\n",
    "        else:\n",
    "            valid_pairs.append(pair)\n",
    "    return valid_pairs\n",
    "\n",
    "raw_gt_pred_pairs = list(zip(all_ground_truths, predictions))\n",
    "gt_pred_pairs = filter_invalid_pairs(raw_gt_pred_pairs)\n",
    "\n",
    "\n",
    "# --- Calculate Metrics ---\n",
    "accuracy = None\n",
    "precision = None\n",
    "recall = None\n",
    "f1 = None\n",
    "abstention_rate = None\n",
    "cm = None\n",
    "\n",
    "if len(gt_pred_pairs) > 0:\n",
    "    TP = len([gt == pred for (gt,pred) in gt_pred_pairs if pred == 1])\n",
    "    TN = len([gt == pred for (gt,pred) in gt_pred_pairs if pred == 0])\n",
    "    FP = len([gt != pred for (gt,pred) in gt_pred_pairs if pred == 1]) # FIX THIS\n",
    "    FN = len([gt != pred for (gt,pred) in gt_pred_pairs if pred == 0]) # FIX THIS\n",
    "    total_valid_preds = len(gt_pred_pairs)\n",
    "    invalid_count = len(raw_gt_pred_pairs) - len(gt_pred_pairs)\n",
    "    abstention_rate = invalid_count / len(raw_gt_pred_pairs)\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    valid_gts = [gt for (gt,pred) in gt_pred_pairs]\n",
    "    valid_preds = [pred for (gt,pred) in gt_pred_pairs]\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        valid_gts, valid_preds, average='binary', pos_label=1, zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(valid_gts, valid_preds, labels=[0,1]) # unused at the moment\n",
    "else:\n",
    "    print(\"No valid predictions were made, skipping metric calculations.\")\n",
    "\n",
    "\n",
    "# --- Save Results ---\n",
    "results_df = []\n",
    "results_df.append({\n",
    "    'Baseline': {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'abstention_rate': abstention_rate}\n",
    "})\n",
    "dp = ConfusionMatrixDisplay(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a4fd6a3-d656-441e-82f7-fb15dd96e64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb72fb67-5788-4b19-b140-a8eb20203dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 0), (0, 0), (1, 1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_pred_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50d19283-937e-420b-a1c5-2c0b9944a2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[gt != pred for (gt,pred) in gt_pred_pairs if pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565f3aa-7e60-469e-a59d-1a676dce2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode('!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66025c-41d5-45b0-aa28-9b63655261c4",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48335133-43b8-4c0c-9175-41d86b897e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset():\n",
    "  print(ds['train'])\n",
    "  i = 0\n",
    "  for row in ds['train']:\n",
    "    if i == 4:\n",
    "      break\n",
    "    question = row['Question']\n",
    "    hallucinated_answer = row['Hallucinated Answer']\n",
    "    ground_truth_answer = row['Ground Truth']\n",
    "    print(ground_truth_answer)\n",
    "    i += 1\n",
    "check_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
