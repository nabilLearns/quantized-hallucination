- model=llama3-med
- quantization=gguf
- quantization.level=q2_k
- max_samples=100
